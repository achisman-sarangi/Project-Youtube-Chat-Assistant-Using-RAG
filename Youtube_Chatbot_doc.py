# -*- coding: utf-8 -*-
"""Project-Youtube Chatbot using RAG .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RPbT4uGLW6cGcBxRD2b7jQwcZ999slao
"""

import os
from dotenv import load_dotenv
load_dotenv()

"""Install Libraries"""

!pip install -q youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings,ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate

"""Indexing"""

video_id = "QT2FGbR0nIM" #give the youtube video id
try:
  #Now if you don't know which language, choose the best one
  transcript_text = YouTubeTranscriptApi.get_transcript(video_id , languages = ['en'])

  transcript = " ".join(chunk["text"] for chunk in transcript_text)
  print(transcript)

except TranscriptsDisabled:
  print("No caption available in this video")

transcript_text #Get the duration of your transcript

"""Indexing(Text splitting)"""

splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)
chunks = splitter.create_documents([transcript])

len(chunks)

chunks[0]

"""Indexing(Embedding Generation & Storing in vector store)"""

embeddings = OpenAIEmbeddings(model = "text-embedding-3-small")
vector_store = FAISS.from_documents(chunks,embeddings)

vector_store.index_to_docstore_id

vector_store.get_by_ids(['516cd4d1-9915-4f91-865e-47e885f340e3'])

"""Retrival"""

retriever = vector_store.as_retriever(serach_type = "similarity",search_kwargs={'k':4})

retriever

retriever.invoke('Tedâ€™s favourite Indian creator')

"""Augmentation"""

llm = ChatOpenAI(model = "gpt-4o-mini", temperature=0.2)

prompt = PromptTemplate(
    template ="""
    you are a helpful assistant.
    Answer ONLY from the provided trsnscript context
    if the context is insufficient, just say you don't know.

    {context}
    Question: {question}
    """,
    input_variables={'context','question'}
)

question = "is the topic of shahRukh khan movie star discussed in this video?if yes then what was discussed"
retriever_docs = retriever.invoke(question)

retriever_docs

context_text = "\n\n".join(doc.page_content for doc in retriever_docs)
context_text

final_prompt = prompt.invoke({"context":context_text ,"question":question})
final_prompt

"""Generation"""

Answer_of_question = llm.invoke(final_prompt)
print(Answer_of_question.content)

"""Building A Chain"""

from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda
from langchain_core.output_parsers import StrOutputParser

def format_docs(retriever_docs):
  context_text = "\n\n".join(doc.page_content for doc in retriever_docs)
  return context_text

parallel_chain = RunnableParallel({
    'context': retriever|RunnableLambda(format_docs),
    'question':RunnablePassthrough()
    })

parallel_chain.invoke("what is next big disruption")

parser = StrOutputParser()

final_chain = parallel_chain|prompt|llm|parser

final_chain.invoke("can you give me  all the name who is mention in  this podcast?")